{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinitvshah/SLM/blob/feature/Train_SLM_Distillation\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f6ca90a",
      "metadata": {
        "id": "6f6ca90a"
      },
      "source": [
        "# Knowledge Distillation: Training a Small Fraud Detection Model\n",
        "## Using Mistral-7B as Teacher to Train a 125M-1B Parameter Student Model\n",
        "\n",
        "This notebook demonstrates **knowledge distillation** to create a small, fast, production-ready fraud detection model:\n",
        "\n",
        "### Architecture\n",
        "- **Teacher Model**: Mistral-7B (7B parameters) - generates soft labels\n",
        "- **Student Model**: Custom transformer (125M-1B parameters) - learns from teacher\n",
        "- **Result**: 10-50x faster inference with 85-95% of teacher's accuracy\n",
        "\n",
        "### Why Knowledge Distillation?\n",
        "| Approach | Training Cost | Inference Speed | Quality | Deployment |\n",
        "|----------|--------------|-----------------|---------|------------|\n",
        "| Fine-tune Mistral-7B | Low | Slow (~500ms) | Best | Hard (28GB GPU) |\n",
        "| Train from Scratch | Very High | Fast | Poor | Easy |\n",
        "| **Knowledge Distillation** | Medium | **Fast (~20ms)** | Good (85-95%) | **Easy** |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f88b45cb",
      "metadata": {
        "id": "f88b45cb"
      },
      "source": [
        "## 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "613678bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "613678bf",
        "outputId": "bf4bff1d-cbb4-4294-dae3-b5a63cca5a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "GPU Configuration for Knowledge Distillation\n",
            "======================================================================\n",
            "‚úÖ GPU Available: NVIDIA A100-SXM4-40GB\n",
            "   Total Memory: 42.47 GB\n",
            "   ‚úÖ Sufficient for teacher + student training\n",
            "\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# INSTALL REQUIRED PACKAGES\n",
        "# ============================================================================\n",
        "# !pip install -U transformers accelerate bitsandbytes\n",
        "# !pip install -U torch torchvision torchaudio\n",
        "# !pip install pandas scikit-learn tqdm tensorrt vllm\n",
        "\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional, Tuple, List, Dict\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import uuid\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# GPU CHECK\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"GPU Configuration for Knowledge Distillation\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
        "    print(f\"   Total Memory: {gpu_memory:.2f} GB\")\n",
        "\n",
        "    if gpu_memory >= 24:\n",
        "        print(\"   ‚úÖ Sufficient for teacher + student training\")\n",
        "    elif gpu_memory >= 16:\n",
        "        print(\"   ‚ö†Ô∏è  Will use aggressive quantization for teacher\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  Limited memory - consider smaller student model\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"‚ùå No GPU available. Training will be very slow.\")\n",
        "\n",
        "print(f\"\\nUsing device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "63d61519",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63d61519",
        "outputId": "109d61af-b31c-4c4f-b403-3f7cee93fa52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Distillation Configuration\n",
            "======================================================================\n",
            "\n",
            "üìä Student Model:\n",
            "   Size: small\n",
            "   Parameters: ~125M\n",
            "   Layers: 6, Heads: 8\n",
            "   Hidden: 512, FFN: 2048\n",
            "\n",
            "üéì Teacher Model: mistralai/Mistral-7B-v0.1\n",
            "\n",
            "‚öôÔ∏è  Training:\n",
            "   Epochs: 10\n",
            "   Batch size: 4 x 4 = 16\n",
            "   Learning rate: 0.0001\n",
            "\n",
            "üî• Distillation:\n",
            "   Temperature: 2.0\n",
            "   Alpha (distill weight): 0.7\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class DistillationConfig:\n",
        "    \"\"\"Configuration for knowledge distillation training\"\"\"\n",
        "\n",
        "    # Student model size: \"tiny\" (25M), \"small\" (125M), \"medium\" (350M), \"large\" (1B)\n",
        "    student_size: str = \"small\"\n",
        "\n",
        "    # Model configurations by size\n",
        "    MODEL_CONFIGS: Dict = field(default_factory=lambda: {\n",
        "        \"tiny\":   {\"n_layers\": 4,  \"n_heads\": 4,  \"d_model\": 256,  \"d_ff\": 1024,  \"params\": \"~25M\"},\n",
        "        \"small\":  {\"n_layers\": 6,  \"n_heads\": 8,  \"d_model\": 512,  \"d_ff\": 2048,  \"params\": \"~125M\"},\n",
        "        \"medium\": {\"n_layers\": 12, \"n_heads\": 12, \"d_model\": 768,  \"d_ff\": 3072,  \"params\": \"~350M\"},\n",
        "        \"large\":  {\"n_layers\": 24, \"n_heads\": 16, \"d_model\": 1024, \"d_ff\": 4096,  \"params\": \"~1B\"},\n",
        "    })\n",
        "\n",
        "    # Training hyperparameters\n",
        "    max_length: int = 512\n",
        "    batch_size: int = 4\n",
        "    gradient_accumulation_steps: int = 4  # Effective batch = 16\n",
        "    learning_rate: float = 1e-4\n",
        "    num_epochs: int = 10\n",
        "    warmup_ratio: float = 0.1\n",
        "    weight_decay: float = 0.01\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # Distillation hyperparameters\n",
        "    temperature: float = 2.0      # Softens teacher probabilities\n",
        "    alpha: float = 0.7            # Weight: distillation vs hard label loss\n",
        "\n",
        "    # Teacher model\n",
        "    teacher_model: str = \"mistralai/Mistral-7B-v0.1\"\n",
        "\n",
        "    # Output paths\n",
        "    output_dir: str = \"./fraud_slm_distilled\"\n",
        "    checkpoint_dir: str = \"./fraud_slm_checkpoints\"\n",
        "\n",
        "config = DistillationConfig()\n",
        "student_cfg = config.MODEL_CONFIGS[config.student_size]\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(config.output_dir, exist_ok=True)\n",
        "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Distillation Configuration\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nüìä Student Model:\")\n",
        "print(f\"   Size: {config.student_size}\")\n",
        "print(f\"   Parameters: {student_cfg['params']}\")\n",
        "print(f\"   Layers: {student_cfg['n_layers']}, Heads: {student_cfg['n_heads']}\")\n",
        "print(f\"   Hidden: {student_cfg['d_model']}, FFN: {student_cfg['d_ff']}\")\n",
        "\n",
        "print(f\"\\nüéì Teacher Model: {config.teacher_model}\")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è  Training:\")\n",
        "print(f\"   Epochs: {config.num_epochs}\")\n",
        "print(f\"   Batch size: {config.batch_size} x {config.gradient_accumulation_steps} = {config.batch_size * config.gradient_accumulation_steps}\")\n",
        "print(f\"   Learning rate: {config.learning_rate}\")\n",
        "\n",
        "print(f\"\\nüî• Distillation:\")\n",
        "print(f\"   Temperature: {config.temperature}\")\n",
        "print(f\"   Alpha (distill weight): {config.alpha}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65d6bda1",
      "metadata": {
        "id": "65d6bda1"
      },
      "source": [
        "## 2. Generate Fraud Training Data\n",
        "\n",
        "Generate 10,000 synthetic records with 1-year historical context for each customer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fd7ee19f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd7ee19f",
        "outputId": "3a0169bd-d13a-4614-9d43-eaae0169d69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Generating Fraud Detection Dataset\n",
            "======================================================================\n",
            "   Processing customer 1/2000...\n",
            "   Processing customer 501/2000...\n",
            "   Processing customer 1001/2000...\n",
            "   Processing customer 1501/2000...\n",
            "\n",
            "‚úÖ Dataset generated:\n",
            "   Total records: 10,000\n",
            "   Unique customers: 2,000\n",
            "   Fraud rate: 14.41%\n",
            "\n",
            "üíæ Dataset saved to CSV:\n",
            "   File path: /content/fraud_training_data.csv\n",
            "   File size: 22.66 MB\n",
            "   Columns: ['customer_id', 'account_id', 'event_id', 'prompt', 'text', 'label', 'label_id', 'current_amount', 'current_merchant', 'history_text']\n",
            "\n",
            "üìù Sample prompt:\n",
            "======================================================================\n",
            "<|system|>\n",
            "You are a fraud detection system. Analyze the transaction history and current transaction to determine if it is FRAUD or LEGITIMATE.\n",
            "<|user|>\n",
            "Customer: CUST_C818B3FDD3 | Account: ACC_E3673993\n",
            "\n",
            "=== TRANSACTION HISTORY ===\n",
            "[2025-10-31] REFUND: Amazon, $393, approved\n",
            "[2025-11-04] REFUND: Chipotle, $451, approved\n",
            "[2025-11-05] TRANSFER: Amazon, $332, approved\n",
            "[2025-11-21] WITHDRAWAL: Walmart, $454, approved\n",
            "[2025-11-23] PAYMENT: Amazon, $25, approved\n",
            "[2025-11-24] REFUND: Shell, $400, approved\n",
            "[2025-12-05] REFUND: Shell, $99, approved\n",
            "[2025-12-11] WITHDRAWAL: Chevron, $262, approved\n",
            "[2025...\n",
            "\n",
            "üìä Data Summary:\n",
            "   Fraud transactions: 1,441\n",
            "   Legitimate transactions: 8,559\n",
            "   Avg current amount (Fraud): $10,962.16\n",
            "   Avg current amount (Legit): $252.94\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# GENERATE FRAUD TRAINING DATA - 10,000 RECORDS WITH 1-YEAR HISTORY\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "def generate_historical_fraud_data(num_customers=2000, events_per_customer=5):\n",
        "    \"\"\"\n",
        "    Generate synthetic fraud dataset with 1-year historical context.\n",
        "\n",
        "    Creates denormalized records with:\n",
        "    - Customer and account identifiers\n",
        "    - 1-year transaction history\n",
        "    - Current transaction details\n",
        "    - Fraud/Legitimate labels\n",
        "\n",
        "    Args:\n",
        "        num_customers: Number of unique customers\n",
        "        events_per_customer: Training samples per customer\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with 10,000 training records\n",
        "    \"\"\"\n",
        "    np.random.seed(42)  # Reproducibility\n",
        "\n",
        "    # Merchant categories\n",
        "    legit_merchants = {\n",
        "        'retail': ['Walmart', 'Target', 'Costco', 'Amazon', 'Best Buy'],\n",
        "        'food': ['McDonalds', 'Starbucks', 'Chipotle', 'Subway', 'Dominos'],\n",
        "        'gas': ['Shell', 'Chevron', 'BP', 'ExxonMobil', 'Valero'],\n",
        "        'utilities': ['Electric Co', 'Gas Utility', 'Water Works', 'Internet Provider']\n",
        "    }\n",
        "\n",
        "    fraud_merchants = [\n",
        "        'CryptoExchange', 'OnlineCasino', 'WireTransfer', 'UnknownMerchant',\n",
        "        'OverseasATM', 'GiftCardStore', 'SuspiciousVendor', 'HighRiskATM'\n",
        "    ]\n",
        "\n",
        "    event_types = ['purchase', 'refund', 'transfer', 'withdrawal', 'payment']\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for i in range(num_customers):\n",
        "        if i % 500 == 0:\n",
        "            print(f\"   Processing customer {i+1}/{num_customers}...\")\n",
        "\n",
        "        customer_id = f\"CUST_{uuid.uuid4().hex[:10].upper()}\"\n",
        "        account_id = f\"ACC_{uuid.uuid4().hex[:8].upper()}\"\n",
        "\n",
        "        # 30% fraud customers\n",
        "        is_fraud_customer = np.random.random() < 0.3\n",
        "\n",
        "        # Generate 1-year history\n",
        "        base_date = datetime.now()\n",
        "        history_events = []\n",
        "\n",
        "        for month_offset in range(12, 0, -1):\n",
        "            num_events = np.random.randint(5, 20)\n",
        "\n",
        "            for _ in range(num_events):\n",
        "                event_date = base_date - timedelta(days=month_offset * 30 + np.random.randint(0, 30))\n",
        "                event_type = np.random.choice(event_types)\n",
        "\n",
        "                # Fraud patterns appear in recent 2 months\n",
        "                if is_fraud_customer and month_offset <= 2 and np.random.random() < 0.4:\n",
        "                    merchant = np.random.choice(fraud_merchants)\n",
        "                    amount = np.random.randint(1000, 15000)\n",
        "                    status = 'suspicious'\n",
        "                else:\n",
        "                    category = np.random.choice(list(legit_merchants.keys()))\n",
        "                    merchant = np.random.choice(legit_merchants[category])\n",
        "                    amount = np.random.randint(10, 500)\n",
        "                    status = 'approved'\n",
        "\n",
        "                history_events.append({\n",
        "                    'date': event_date.strftime('%Y-%m-%d'),\n",
        "                    'type': event_type,\n",
        "                    'merchant': merchant,\n",
        "                    'amount': amount,\n",
        "                    'status': status\n",
        "                })\n",
        "\n",
        "        history_events.sort(key=lambda x: x['date'])\n",
        "\n",
        "        # Create training samples\n",
        "        for _ in range(events_per_customer):\n",
        "            event_id = f\"EVT_{uuid.uuid4().hex[:8].upper()}\"\n",
        "            context_size = min(10, len(history_events))\n",
        "            recent_history = history_events[-context_size:]\n",
        "\n",
        "            # Build history text\n",
        "            history_text = \"\\n\".join([\n",
        "                f\"[{evt['date']}] {evt['type'].upper()}: {evt['merchant']}, ${evt['amount']}, {evt['status']}\"\n",
        "                for evt in recent_history\n",
        "            ])\n",
        "\n",
        "            # Current transaction\n",
        "            current_date = base_date.strftime('%Y-%m-%d')\n",
        "            if is_fraud_customer and np.random.random() < 0.5:\n",
        "                current_merchant = np.random.choice(fraud_merchants)\n",
        "                current_amount = np.random.randint(2000, 20000)\n",
        "                label = \"FRAUD\"\n",
        "                label_id = 1\n",
        "            else:\n",
        "                category = np.random.choice(list(legit_merchants.keys()))\n",
        "                current_merchant = np.random.choice(legit_merchants[category])\n",
        "                current_amount = np.random.randint(10, 500)\n",
        "                label = \"LEGITIMATE\"\n",
        "                label_id = 0\n",
        "\n",
        "            # Format prompt\n",
        "            prompt = f\"\"\"<|system|>\n",
        "You are a fraud detection system. Analyze the transaction history and current transaction to determine if it is FRAUD or LEGITIMATE.\n",
        "<|user|>\n",
        "Customer: {customer_id} | Account: {account_id}\n",
        "\n",
        "=== TRANSACTION HISTORY ===\n",
        "{history_text}\n",
        "\n",
        "=== CURRENT TRANSACTION ===\n",
        "[{current_date}] {current_merchant}, ${current_amount}\n",
        "\n",
        "Is this transaction FRAUD or LEGITIMATE?\n",
        "<|assistant|>\n",
        "Based on the transaction history and current transaction, this is: \"\"\"\n",
        "\n",
        "            # Full text includes label (for training)\n",
        "            full_text = prompt + label\n",
        "\n",
        "            records.append({\n",
        "                'customer_id': customer_id,\n",
        "                'account_id': account_id,\n",
        "                'event_id': event_id,\n",
        "                'prompt': prompt,\n",
        "                'text': full_text,\n",
        "                'label': label,\n",
        "                'label_id': label_id,\n",
        "                'current_amount': current_amount,\n",
        "                'current_merchant': current_merchant,\n",
        "                'history_text': history_text\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "\n",
        "# Generate dataset\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Generating Fraud Detection Dataset\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "df = generate_historical_fraud_data(num_customers=2000, events_per_customer=5)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset generated:\")\n",
        "print(f\"   Total records: {len(df):,}\")\n",
        "print(f\"   Unique customers: {df['customer_id'].nunique():,}\")\n",
        "print(f\"   Fraud rate: {(df['label'] == 'FRAUD').mean():.2%}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SAVE DATASET TO CSV FILE (Current working directory)\n",
        "# ============================================================================\n",
        "\n",
        "# Use current working directory\n",
        "CSV_FILE = \"fraud_training_data.csv\"\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(CSV_FILE, index=False)\n",
        "\n",
        "print(f\"\\nüíæ Dataset saved to CSV:\")\n",
        "print(f\"   File path: {os.path.abspath(CSV_FILE)}\")\n",
        "print(f\"   File size: {os.path.getsize(CSV_FILE) / (1024*1024):.2f} MB\")\n",
        "print(f\"   Columns: {list(df.columns)}\")\n",
        "\n",
        "print(f\"\\nüìù Sample prompt:\")\n",
        "print(\"=\" * 70)\n",
        "print(df.iloc[0]['prompt'][:600] + \"...\")\n",
        "\n",
        "# Display data summary\n",
        "print(f\"\\nüìä Data Summary:\")\n",
        "print(f\"   Fraud transactions: {(df['label'] == 'FRAUD').sum():,}\")\n",
        "print(f\"   Legitimate transactions: {(df['label'] == 'LEGITIMATE').sum():,}\")\n",
        "print(f\"   Avg current amount (Fraud): ${df[df['label'] == 'FRAUD']['current_amount'].mean():,.2f}\")\n",
        "print(f\"   Avg current amount (Legit): ${df[df['label'] == 'LEGITIMATE']['current_amount'].mean():,.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "052137ac",
      "metadata": {
        "id": "052137ac"
      },
      "source": [
        "### 2.1 Verify CSV File\n",
        "\n",
        "Quick verification that the data was successfully saved to the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f25ad2",
      "metadata": {
        "id": "f5f25ad2",
        "outputId": "56c265ef-a265-4857-8028-f0c864382523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CSV File Verification\n",
            "======================================================================\n",
            "\n",
            "‚úÖ CSV file found and loaded successfully!\n",
            "   File path: /content/fraud_training_data.csv\n",
            "   File size: 22.66 MB\n",
            "\n",
            "üìä Dataset Statistics:\n",
            "   Total records: 10,000\n",
            "   Columns: 10\n",
            "   Column names: ['customer_id', 'account_id', 'event_id', 'prompt', 'text', 'label', 'label_id', 'current_amount', 'current_merchant', 'history_text']\n",
            "\n",
            "üìà Data Distribution:\n",
            "   Unique customers: 2,000\n",
            "   Fraud transactions: 1,441\n",
            "   Legitimate transactions: 8,559\n",
            "   Fraud rate: 14.41%\n",
            "\n",
            "üìù First 3 records preview:\n",
            "----------------------------------------------------------------------\n",
            "       customer_id      event_id       label   current_merchant  \\\n",
            "0  CUST_4E7A471006  EVT_B0ACCBC8  LEGITIMATE        Gas Utility   \n",
            "1  CUST_4E7A471006  EVT_B5295066  LEGITIMATE             Costco   \n",
            "2  CUST_4E7A471006  EVT_31C7C755  LEGITIMATE  Internet Provider   \n",
            "\n",
            "   current_amount  \n",
            "0             123  \n",
            "1             422  \n",
            "2             226  \n",
            "\n",
            "‚úÖ CSV file verification complete!\n",
            "\n",
            "‚úÖ CSV file found and loaded successfully!\n",
            "   File path: /content/fraud_training_data.csv\n",
            "   File size: 22.66 MB\n",
            "\n",
            "üìä Dataset Statistics:\n",
            "   Total records: 10,000\n",
            "   Columns: 10\n",
            "   Column names: ['customer_id', 'account_id', 'event_id', 'prompt', 'text', 'label', 'label_id', 'current_amount', 'current_merchant', 'history_text']\n",
            "\n",
            "üìà Data Distribution:\n",
            "   Unique customers: 2,000\n",
            "   Fraud transactions: 1,441\n",
            "   Legitimate transactions: 8,559\n",
            "   Fraud rate: 14.41%\n",
            "\n",
            "üìù First 3 records preview:\n",
            "----------------------------------------------------------------------\n",
            "       customer_id      event_id       label   current_merchant  \\\n",
            "0  CUST_4E7A471006  EVT_B0ACCBC8  LEGITIMATE        Gas Utility   \n",
            "1  CUST_4E7A471006  EVT_B5295066  LEGITIMATE             Costco   \n",
            "2  CUST_4E7A471006  EVT_31C7C755  LEGITIMATE  Internet Provider   \n",
            "\n",
            "   current_amount  \n",
            "0             123  \n",
            "1             422  \n",
            "2             226  \n",
            "\n",
            "‚úÖ CSV file verification complete!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# VERIFY CSV FILE WAS CREATED AND POPULATED\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "CSV_FILE = \"fraud_training_data.csv\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CSV File Verification\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check if file exists\n",
        "if os.path.exists(CSV_FILE):\n",
        "    # Read the CSV file\n",
        "    df_verify = pd.read_csv(CSV_FILE)\n",
        "\n",
        "    print(f\"\\n‚úÖ CSV file found and loaded successfully!\")\n",
        "    print(f\"   File path: {os.path.abspath(CSV_FILE)}\")\n",
        "    print(f\"   File size: {os.path.getsize(CSV_FILE) / (1024*1024):.2f} MB\")\n",
        "\n",
        "    print(f\"\\nüìä Dataset Statistics:\")\n",
        "    print(f\"   Total records: {len(df_verify):,}\")\n",
        "    print(f\"   Columns: {len(df_verify.columns)}\")\n",
        "    print(f\"   Column names: {list(df_verify.columns)}\")\n",
        "\n",
        "    print(f\"\\nüìà Data Distribution:\")\n",
        "    print(f\"   Unique customers: {df_verify['customer_id'].nunique():,}\")\n",
        "    print(f\"   Fraud transactions: {(df_verify['label'] == 'FRAUD').sum():,}\")\n",
        "    print(f\"   Legitimate transactions: {(df_verify['label'] == 'LEGITIMATE').sum():,}\")\n",
        "    print(f\"   Fraud rate: {(df_verify['label'] == 'FRAUD').mean():.2%}\")\n",
        "\n",
        "    print(f\"\\nüìù First 3 records preview:\")\n",
        "    print(\"-\" * 70)\n",
        "    print(df_verify[['customer_id', 'event_id', 'label', 'current_merchant', 'current_amount']].head(3))\n",
        "\n",
        "    print(f\"\\n‚úÖ CSV file verification complete!\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n‚ùå CSV file not found!\")\n",
        "    print(f\"   Expected path: {os.path.abspath(CSV_FILE)}\")\n",
        "    print(f\"\\nüí° Please run the data generation cell (Step 2) above to create the file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5168a3cb",
      "metadata": {
        "id": "5168a3cb"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DOWNLOAD CSV FILE (Google Colab Only)\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "CSV_FILE = \"fraud_training_data.csv\"\n",
        "\n",
        "# Check current working directory\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"CSV file path: {os.path.abspath(CSV_FILE)}\")\n",
        "\n",
        "# Option 1: Download file directly (Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\\nüì• Google Colab detected - downloading file...\")\n",
        "    files.download(CSV_FILE)\n",
        "    print(\"‚úÖ File downloaded to your local Downloads folder!\")\n",
        "except ImportError:\n",
        "    print(\"\\n‚úÖ Running locally - file is already in your workspace!\")\n",
        "    print(f\"   Location: {os.path.abspath(CSV_FILE)}\")\n",
        "\n",
        "    # Verify file exists locally\n",
        "    if os.path.exists(CSV_FILE):\n",
        "        file_size = os.path.getsize(CSV_FILE)\n",
        "        if file_size > 0:\n",
        "            print(f\"   File size: {file_size / (1024*1024):.2f} MB\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è WARNING: File is empty (0 bytes)\")\n",
        "            print(f\"   Please run Step 2 (data generation cell) above to populate the file.\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå File does not exist!\")\n",
        "        print(f\"   Please run Step 2 (data generation cell) above to create the file.\")\n",
        "\n",
        "# Option 2: Save to Google Drive (uncomment if needed)\n",
        "# try:\n",
        "#     from google.colab import drive\n",
        "#     drive.mount('/content/drive')\n",
        "#     import shutil\n",
        "#     shutil.copy(CSV_FILE, '/content/drive/MyDrive/fraud_training_data.csv')\n",
        "#     print(\"‚úÖ File saved to Google Drive: MyDrive/fraud_training_data.csv\")\n",
        "# except:\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53ebbe5",
      "metadata": {
        "id": "d53ebbe5"
      },
      "source": [
        "### 2.2 Download CSV File (For Google Colab Users)\n",
        "\n",
        "If you're running in Google Colab, use this cell to download the CSV file to your local machine or save it to Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5386586d",
      "metadata": {
        "id": "5386586d"
      },
      "source": [
        "## 3. Load Teacher Model (Mistral-7B)\n",
        "\n",
        "Load Mistral-7B with 4-bit quantization to generate soft labels."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INSTALL REQUIRED PACKAGES\n",
        "# ============================================================================\n",
        "# 'accelerate' is REQUIRED for device_map=\"auto\" and 4-bit quantization\n",
        "!pip install -U bitsandbytes accelerate transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XoZZeaCBU39c",
        "outputId": "ed0b3738-5c98-4c11-d5ca-8e2fddeccd9c"
      },
      "id": "XoZZeaCBU39c",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "04a823e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435,
          "referenced_widgets": [
            "8827dc3d417140099791f7b31f68cc7e",
            "d40b7dbdeb5c4359b9d4555ae70dc12d",
            "d9a5528279f649dc97eecb12fe748b0a",
            "587045d2db0041ecb72895eee406bd27",
            "82c6c918b7344bfabfcddc8caf19d25f",
            "beb50b99d0764c25b9f7d5bbb6f358d5",
            "e59b3078260a4e028c62ea4c3b34cc50",
            "1de2ce0e88e249b1814d8360e1b51ed6",
            "dcc9d1f713d7461595b97bd6835ab30d",
            "b89fff611cb248329b6d451fd04341a8",
            "130e7429d0ab49958005dab8d9fcc9fc",
            "c11bed3b69db4648b1c94ea9fad9ffb6",
            "b25e626579b54f918aad88d7810b3308",
            "c539ad5a904a427a95092881105b947d",
            "e909537c900e456199b31b4f71668c74",
            "cd17220981c545958da82f567c0bc3fc",
            "aab9495e3a9b420383717902899a3557",
            "bf000801bc7541d9bd37aa66e4e3682c",
            "ecb9c037aa3b4487995de13fe9973435",
            "786b315733754913ae58ffacb1207eb3",
            "33ef0be5d6ef4e6cac6506403160fe41",
            "108ae18cf36d4cb089a90d5055241c53",
            "1448392265e7465895588459f5a25185",
            "efaadf4823f145fbb706fb1a33bf012c",
            "f493162ea28b46d6b0126a3420ee19bb",
            "68b604ea78ca4e50ad4e6de310c06844",
            "55cc2155088844c48e6be67f501269c2",
            "11f156600b8b40348de9a5ef5f88e751",
            "6a69ed3cb4b048d59fa6ead734e0f661",
            "977f3c9c67a84fc6a9cb0801df5351f9",
            "fb322ad1e9414b908133cc44c9b8cf58",
            "15f7bd953c56426ea595fde62e526cdf",
            "cb179d85a75441138082347b48f942e8",
            "c6d142e6083149b9b49abeee3f2f3f33",
            "7879caa643e64a90b54b1e44f9403a87",
            "2169fea9afa14d7a908fd910e8cfabcc",
            "1fa39fa6987c4da18fa333e82f24240e",
            "bf5f2dcffabb40f3bfbb83d8a7f22b43",
            "b05167f92bb54283b32ac9b316806f56",
            "d49d89150c3a4f1fb145527486fbef7f",
            "ba5e98b6ff3a4a6a92ad75f3c6094ef4",
            "4b247ee29c6f4f15a063026a5d585477",
            "8a3c8fb69e064517846966dae503931d",
            "7bf0bbb6247e415e8b5f986556ac7dab",
            "88eae737800940d782d615334cb0e8b4",
            "dbbbd4400ef74df89e2aedf352c539cc",
            "7aada6e682e94b3c9f7d88c417c48ea5",
            "42e119d315084de484ca9bd38fab2859",
            "57c1e8ab872a49359ff8532c0ac6518a",
            "a572f01d4d0b419b855ec46a012c6a6f",
            "b9a8f8e5653f4baeaca353d1b599e450",
            "e583691e198e46988345fc4c4f073a1a",
            "7258539794ac4cb3ae65dc58dc1d4f7a",
            "546f8e2a055244f3b2b0a088188d88cb",
            "1e2e837adf0744339408332ab970ff0a",
            "5f028a8721f04ec7883af679ebc19cc7",
            "e8bf841b9b6247c38e87c04077f7d5a6",
            "aac3d996a6df4ae98d1eb2a9e4cdf038",
            "f654ad61647d4a719f03c29b8fac535d",
            "5a58b78752be4895b27f3b3de2b1d6cd",
            "50c757282bcb426bbb575e4c87607c3f",
            "060e3079a5f14f7082f7d12dd211871d",
            "33d4ec50f98d45de8f7fa30fbfe5aed8",
            "058e6672ab4d4bfea3515808f7f6e095",
            "157f5a2ff62f4fd3b2df844fd9759edb",
            "dc8e077b90994f44b705e0b9108213ee"
          ]
        },
        "id": "04a823e0",
        "outputId": "ddecb080-95fb-4f23-fd20-6cd0ec6cec5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Loading Teacher Model: Mistral-7B\n",
            "======================================================================\n",
            "   ‚úÖ bitsandbytes version: 0.49.1\n",
            "\n",
            "üì• Loading tokenizer...\n",
            "   ‚úÖ Tokenizer loaded: vocab_size=32,000\n",
            "\n",
            "üì• Loading mistralai/Mistral-7B-v0.1...\n",
            "   (This may take a few minutes for first download)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8827dc3d417140099791f7b31f68cc7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c11bed3b69db4648b1c94ea9fad9ffb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1448392265e7465895588459f5a25185"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6d142e6083149b9b49abeee3f2f3f33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88eae737800940d782d615334cb0e8b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f028a8721f04ec7883af679ebc19cc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Teacher model loaded\n",
            "   GPU Memory used: ~4.13 GB\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# LOAD TEACHER MODEL (MISTRAL-7B)\n",
        "# ============================================================================\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import bitsandbytes as bnb  # Explicit import to check availability\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Check if config is defined\n",
        "try:\n",
        "    config\n",
        "except NameError:\n",
        "    raise NameError(\"The 'config' variable is not defined. Please run the Configuration cell (Step 1) above before running this cell.\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Loading Teacher Model: Mistral-7B\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    print(f\"   ‚úÖ bitsandbytes version: {bnb.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ö†Ô∏è Error importing bitsandbytes directly: {e}\")\n",
        "\n",
        "# 4-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "print(\"\\nüì• Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    config.teacher_model,\n",
        "    trust_remote_code=True,\n",
        "    padding_side=\"right\",\n",
        ")\n",
        "\n",
        "# Set special tokens\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print(f\"   ‚úÖ Tokenizer loaded: vocab_size={tokenizer.vocab_size:,}\")\n",
        "\n",
        "# Load teacher model\n",
        "print(f\"\\nüì• Loading {config.teacher_model}...\")\n",
        "print(\"   (This may take a few minutes for first download)\")\n",
        "\n",
        "try:\n",
        "    teacher_model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.teacher_model,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        dtype=torch.float16,\n",
        "    )\n",
        "except ImportError as e:\n",
        "    if \"bitsandbytes\" in str(e) or \"accelerate\" in str(e):\n",
        "        print(\"\\n‚ùå IMPORT ERROR CAUGHT\")\n",
        "        print(\"It seems required libraries (bitsandbytes or accelerate) are missing or not loaded.\")\n",
        "        print(\"1. Ensure you ran the '!pip install' cell above.\")\n",
        "        print(\"2. RESTART THE RUNTIME: Click 'Runtime' > 'Restart session' in the menu.\")\n",
        "        print(\"3. Re-run the cells starting from the imports.\")\n",
        "    raise e\n",
        "\n",
        "teacher_model.eval()\n",
        "\n",
        "# Disable gradient computation for teacher\n",
        "for param in teacher_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(f\"\\n‚úÖ Teacher model loaded\")\n",
        "print(f\"   GPU Memory used: ~{torch.cuda.memory_allocated()/1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3fcaa2f",
      "metadata": {
        "id": "c3fcaa2f"
      },
      "source": [
        "## 4. Define Student Model Architecture\n",
        "\n",
        "Create a custom small transformer with the same architecture style as Mistral (RoPE, SwiGLU, RMSNorm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "559fc0a5",
      "metadata": {
        "id": "559fc0a5"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STUDENT MODEL ARCHITECTURE\n",
        "# ============================================================================\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    \"\"\"Root Mean Square Layer Normalization (like LLaMA/Mistral)\"\"\"\n",
        "    def __init__(self, dim: int, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        rms = torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "        return x * rms * self.weight\n",
        "\n",
        "\n",
        "class RotaryPositionalEmbedding(nn.Module):\n",
        "    \"\"\"Rotary Position Embedding (RoPE)\"\"\"\n",
        "    def __init__(self, dim: int, max_seq_len: int = 2048, base: int = 10000):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer('inv_freq', inv_freq)\n",
        "        self._build_cache(max_seq_len)\n",
        "\n",
        "    def _build_cache(self, seq_len: int):\n",
        "        t = torch.arange(seq_len, device=self.inv_freq.device)\n",
        "        freqs = torch.einsum('i,j->ij', t, self.inv_freq)\n",
        "        emb = torch.cat([freqs, freqs], dim=-1)\n",
        "        self.register_buffer('cos_cached', emb.cos())\n",
        "        self.register_buffer('sin_cached', emb.sin())\n",
        "\n",
        "    def forward(self, seq_len: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        return self.cos_cached[:seq_len], self.sin_cached[:seq_len]\n",
        "\n",
        "\n",
        "def rotate_half(x: torch.Tensor) -> torch.Tensor:\n",
        "    x1, x2 = x[..., :x.shape[-1]//2], x[..., x.shape[-1]//2:]\n",
        "    return torch.cat([-x2, x1], dim=-1)\n",
        "\n",
        "\n",
        "def apply_rotary_pos_emb(q: torch.Tensor, k: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor):\n",
        "    cos = cos.unsqueeze(0).unsqueeze(0)\n",
        "    sin = sin.unsqueeze(0).unsqueeze(0)\n",
        "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
        "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
        "    return q_embed, k_embed\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-head self-attention with RoPE\"\"\"\n",
        "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = d_model // n_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.k_proj = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v_proj = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.o_proj = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.rope = RotaryPositionalEmbedding(self.head_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        B, L, _ = x.shape\n",
        "\n",
        "        # Project to Q, K, V\n",
        "        q = self.q_proj(x).view(B, L, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.k_proj(x).view(B, L, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.v_proj(x).view(B, L, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Apply RoPE\n",
        "        cos, sin = self.rope(L)\n",
        "        cos, sin = cos.to(x.device), sin.to(x.device)\n",
        "        q, k = apply_rotary_pos_emb(q, k, cos, sin)\n",
        "\n",
        "        # Attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        # Causal mask\n",
        "        causal_mask = torch.triu(torch.ones(L, L, device=x.device, dtype=torch.bool), diagonal=1)\n",
        "        scores = scores.masked_fill(causal_mask, float('-inf'))\n",
        "\n",
        "        # Padding mask\n",
        "        if attention_mask is not None:\n",
        "            padding_mask = (attention_mask == 0).unsqueeze(1).unsqueeze(2)\n",
        "            scores = scores.masked_fill(padding_mask, float('-inf'))\n",
        "\n",
        "        # Softmax and apply to values\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        out = torch.matmul(attn_weights, v)\n",
        "        out = out.transpose(1, 2).contiguous().view(B, L, -1)\n",
        "\n",
        "        return self.o_proj(out)\n",
        "\n",
        "\n",
        "class SwiGLUFeedForward(nn.Module):\n",
        "    \"\"\"SwiGLU Feed-Forward Network (like LLaMA/Mistral)\"\"\"\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.gate_proj = nn.Linear(d_model, d_ff, bias=False)\n",
        "        self.up_proj = nn.Linear(d_model, d_ff, bias=False)\n",
        "        self.down_proj = nn.Linear(d_ff, d_model, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.dropout(self.down_proj(F.silu(self.gate_proj(x)) * self.up_proj(x)))\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"Transformer block with pre-norm architecture\"\"\"\n",
        "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.feed_forward = SwiGLUFeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = RMSNorm(d_model)\n",
        "        self.norm2 = RMSNorm(d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        x = x + self.attention(self.norm1(x), attention_mask)\n",
        "        x = x + self.feed_forward(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class FraudDetectionSLM(nn.Module):\n",
        "    \"\"\"\n",
        "    Small Language Model for Fraud Detection.\n",
        "    Architecture mirrors Mistral/LLaMA but with fewer parameters.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        d_model: int = 512,\n",
        "        n_layers: int = 6,\n",
        "        n_heads: int = 8,\n",
        "        d_ff: int = 2048,\n",
        "        max_seq_len: int = 512,\n",
        "        dropout: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # Token embeddings\n",
        "        self.embed_tokens = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        # Output\n",
        "        self.norm = RMSNorm(d_model)\n",
        "        self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
        "\n",
        "        # Weight tying\n",
        "        self.lm_head.weight = self.embed_tokens.weight\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        return_hidden: bool = False,\n",
        "    ) -> torch.Tensor:\n",
        "        x = self.embed_tokens(input_ids)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, attention_mask)\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        if return_hidden:\n",
        "            return x\n",
        "\n",
        "        logits = self.lm_head(x)\n",
        "        return logits\n",
        "\n",
        "    def count_parameters(self) -> Tuple[int, int]:\n",
        "        total = sum(p.numel() for p in self.parameters())\n",
        "        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "        return total, trainable\n",
        "\n",
        "\n",
        "# Create student model\n",
        "print(\"=\" * 70)\n",
        "print(f\"Creating Student Model ({config.student_size.upper()})\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "student_model = FraudDetectionSLM(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    d_model=student_cfg['d_model'],\n",
        "    n_layers=student_cfg['n_layers'],\n",
        "    n_heads=student_cfg['n_heads'],\n",
        "    d_ff=student_cfg['d_ff'],\n",
        "    max_seq_len=config.max_length,\n",
        "    dropout=0.1,\n",
        ").to(device)\n",
        "\n",
        "total_params, trainable_params = student_model.count_parameters()\n",
        "\n",
        "print(f\"\\n‚úÖ Student model created\")\n",
        "print(f\"   Total parameters: {total_params:,} ({total_params/1e6:.1f}M)\")\n",
        "print(f\"   Trainable: {trainable_params:,}\")\n",
        "print(f\"   Architecture: {student_cfg['n_layers']} layers, {student_cfg['n_heads']} heads\")\n",
        "print(f\"   Dimensions: d_model={student_cfg['d_model']}, d_ff={student_cfg['d_ff']}\")\n",
        "\n",
        "# Compare sizes\n",
        "teacher_params = 7e9  # Mistral-7B\n",
        "compression_ratio = teacher_params / total_params\n",
        "print(f\"\\nüìä Compression: {compression_ratio:.0f}x smaller than teacher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2243a54f",
      "metadata": {
        "id": "2243a54f"
      },
      "source": [
        "## 5. Prepare Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d595b56c",
      "metadata": {
        "id": "d595b56c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DATASET AND DATALOADERS\n",
        "# ============================================================================\n",
        "\n",
        "class DistillationDataset(Dataset):\n",
        "    \"\"\"Dataset for knowledge distillation training\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_length: int = 512):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict:\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Tokenize full text (prompt + label)\n",
        "        encoding = self.tokenizer(\n",
        "            row['text'],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Create labels (shift input_ids for causal LM)\n",
        "        labels = encoding['input_ids'].squeeze().clone()\n",
        "\n",
        "        # Mask padding tokens in labels\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': labels,\n",
        "            'label_id': torch.tensor(row['label_id']),\n",
        "        }\n",
        "\n",
        "\n",
        "# Split data\n",
        "print(\"=\" * 70)\n",
        "print(\"Preparing Datasets\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.1, random_state=42, stratify=df['label_id']\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Data split:\")\n",
        "print(f\"   Training: {len(train_df):,} samples\")\n",
        "print(f\"   Validation: {len(val_df):,} samples\")\n",
        "print(f\"   Train fraud rate: {train_df['label_id'].mean():.2%}\")\n",
        "print(f\"   Val fraud rate: {val_df['label_id'].mean():.2%}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = DistillationDataset(train_df, tokenizer, config.max_length)\n",
        "val_dataset = DistillationDataset(val_df, tokenizer, config.max_length)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ DataLoaders created\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a9809b",
      "metadata": {
        "id": "02a9809b"
      },
      "source": [
        "## 6. Knowledge Distillation Training\n",
        "\n",
        "Train the student model using:\n",
        "1. **Soft labels** from teacher (KL divergence loss)\n",
        "2. **Hard labels** from ground truth (cross-entropy loss)\n",
        "\n",
        "Combined loss: `L = Œ± * KL_loss + (1-Œ±) * CE_loss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510d285c",
      "metadata": {
        "id": "510d285c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DISTILLATION LOSS\n",
        "# ============================================================================\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined loss for knowledge distillation:\n",
        "    L = Œ± * KL(student || teacher) + (1-Œ±) * CE(student, hard_labels)\n",
        "    \"\"\"\n",
        "    def __init__(self, temperature: float = 2.0, alpha: float = 0.7):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        student_logits: torch.Tensor,  # (B, L, V)\n",
        "        teacher_logits: torch.Tensor,  # (B, L, V)\n",
        "        labels: torch.Tensor,          # (B, L)\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "\n",
        "        # Reshape for loss computation\n",
        "        B, L, V = student_logits.shape\n",
        "        student_flat = student_logits.view(-1, V)\n",
        "        teacher_flat = teacher_logits.view(-1, V)\n",
        "        labels_flat = labels.view(-1)\n",
        "\n",
        "        # Mask for valid positions (non-padding)\n",
        "        valid_mask = labels_flat != -100\n",
        "\n",
        "        if valid_mask.sum() == 0:\n",
        "            return torch.tensor(0.0, device=student_logits.device), \\\n",
        "                   torch.tensor(0.0, device=student_logits.device), \\\n",
        "                   torch.tensor(0.0, device=student_logits.device)\n",
        "\n",
        "        # Apply mask\n",
        "        student_valid = student_flat[valid_mask]\n",
        "        teacher_valid = teacher_flat[valid_mask]\n",
        "        labels_valid = labels_flat[valid_mask]\n",
        "\n",
        "        # Soft label loss (KL divergence with temperature)\n",
        "        soft_student = F.log_softmax(student_valid / self.temperature, dim=-1)\n",
        "        soft_teacher = F.softmax(teacher_valid / self.temperature, dim=-1)\n",
        "\n",
        "        kl_loss = F.kl_div(\n",
        "            soft_student,\n",
        "            soft_teacher,\n",
        "            reduction='batchmean'\n",
        "        ) * (self.temperature ** 2)\n",
        "\n",
        "        # Hard label loss (cross-entropy)\n",
        "        ce_loss = self.ce_loss(student_flat, labels_flat)\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * kl_loss + (1 - self.alpha) * ce_loss\n",
        "\n",
        "        return total_loss, kl_loss, ce_loss\n",
        "\n",
        "\n",
        "# Create loss function\n",
        "distill_loss_fn = DistillationLoss(\n",
        "    temperature=config.temperature,\n",
        "    alpha=config.alpha\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Distillation loss function created\")\n",
        "print(f\"   Temperature: {config.temperature}\")\n",
        "print(f\"   Alpha (distill weight): {config.alpha}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03b5d6db",
      "metadata": {
        "id": "03b5d6db"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TRAINING LOOP\n",
        "# ============================================================================\n",
        "\n",
        "def train_distillation(\n",
        "    student_model: nn.Module,\n",
        "    teacher_model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    config: DistillationConfig,\n",
        "    device: torch.device,\n",
        "):\n",
        "    \"\"\"\n",
        "    Main training loop for knowledge distillation.\n",
        "    \"\"\"\n",
        "    # Optimizer\n",
        "    optimizer = AdamW(\n",
        "        student_model.parameters(),\n",
        "        lr=config.learning_rate,\n",
        "        weight_decay=config.weight_decay,\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    total_steps = len(train_loader) * config.num_epochs\n",
        "    warmup_steps = int(total_steps * config.warmup_ratio)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=config.learning_rate,\n",
        "        total_steps=total_steps,\n",
        "        pct_start=config.warmup_ratio,\n",
        "        anneal_strategy='cos',\n",
        "    )\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = DistillationLoss(config.temperature, config.alpha)\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [], 'train_kl': [], 'train_ce': [],\n",
        "        'val_loss': [], 'val_kl': [], 'val_ce': [],\n",
        "    }\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"Starting Knowledge Distillation Training\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Total steps: {total_steps}\")\n",
        "    print(f\"Warmup steps: {warmup_steps}\")\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        # ========== Training ==========\n",
        "        student_model.train()\n",
        "        train_losses = {'total': 0, 'kl': 0, 'ce': 0}\n",
        "        num_batches = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.num_epochs} [Train]\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            # Move to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Get teacher logits (no grad)\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                )\n",
        "                teacher_logits = teacher_outputs.logits.detach()\n",
        "\n",
        "            # Get student logits\n",
        "            student_logits = student_model(input_ids, attention_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            total_loss, kl_loss, ce_loss = loss_fn(\n",
        "                student_logits, teacher_logits, labels\n",
        "            )\n",
        "\n",
        "            # Scale loss for gradient accumulation\n",
        "            scaled_loss = total_loss / config.gradient_accumulation_steps\n",
        "            scaled_loss.backward()\n",
        "\n",
        "            # Gradient accumulation step\n",
        "            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    student_model.parameters(), config.max_grad_norm\n",
        "                )\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Track losses\n",
        "            train_losses['total'] += total_loss.item()\n",
        "            train_losses['kl'] += kl_loss.item()\n",
        "            train_losses['ce'] += ce_loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'loss': f\"{total_loss.item():.4f}\",\n",
        "                'kl': f\"{kl_loss.item():.4f}\",\n",
        "                'ce': f\"{ce_loss.item():.4f}\",\n",
        "                'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
        "            })\n",
        "\n",
        "        # Average training losses\n",
        "        for key in train_losses:\n",
        "            train_losses[key] /= num_batches\n",
        "\n",
        "        # ========== Validation ==========\n",
        "        student_model.eval()\n",
        "        val_losses = {'total': 0, 'kl': 0, 'ce': 0}\n",
        "        num_val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.num_epochs} [Val]\"):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                # Teacher logits\n",
        "                teacher_outputs = teacher_model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                )\n",
        "                teacher_logits = teacher_outputs.logits\n",
        "\n",
        "                # Student logits\n",
        "                student_logits = student_model(input_ids, attention_mask)\n",
        "\n",
        "                # Compute loss\n",
        "                total_loss, kl_loss, ce_loss = loss_fn(\n",
        "                    student_logits, teacher_logits, labels\n",
        "                )\n",
        "\n",
        "                val_losses['total'] += total_loss.item()\n",
        "                val_losses['kl'] += kl_loss.item()\n",
        "                val_losses['ce'] += ce_loss.item()\n",
        "                num_val_batches += 1\n",
        "\n",
        "        # Average validation losses\n",
        "        for key in val_losses:\n",
        "            val_losses[key] /= num_val_batches\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_losses['total'])\n",
        "        history['train_kl'].append(train_losses['kl'])\n",
        "        history['train_ce'].append(train_losses['ce'])\n",
        "        history['val_loss'].append(val_losses['total'])\n",
        "        history['val_kl'].append(val_losses['kl'])\n",
        "        history['val_ce'].append(val_losses['ce'])\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nüìä Epoch {epoch+1}/{config.num_epochs}:\")\n",
        "        print(f\"   Train - Loss: {train_losses['total']:.4f}, KL: {train_losses['kl']:.4f}, CE: {train_losses['ce']:.4f}\")\n",
        "        print(f\"   Val   - Loss: {val_losses['total']:.4f}, KL: {val_losses['kl']:.4f}, CE: {val_losses['ce']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_losses['total'] < best_val_loss:\n",
        "            best_val_loss = val_losses['total']\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': student_model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_loss': val_losses['total'],\n",
        "                'config': student_cfg,\n",
        "            }, os.path.join(config.checkpoint_dir, 'best_model.pt'))\n",
        "            print(f\"   ‚úÖ New best model saved!\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': student_model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'history': history,\n",
        "            }, os.path.join(config.checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt'))\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "# Run training\n",
        "history = train_distillation(\n",
        "    student_model=student_model,\n",
        "    teacher_model=teacher_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    config=config,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ Training Complete!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbdf9b14",
      "metadata": {
        "id": "dbdf9b14"
      },
      "source": [
        "## 7. Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d29493",
      "metadata": {
        "id": "e5d29493"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAVE FINAL MODEL\n",
        "# ============================================================================\n",
        "\n",
        "# Load best checkpoint\n",
        "best_checkpoint = torch.load(os.path.join(config.checkpoint_dir, 'best_model.pt'))\n",
        "student_model.load_state_dict(best_checkpoint['model_state_dict'])\n",
        "\n",
        "# Save model and config\n",
        "torch.save({\n",
        "    'model_state_dict': student_model.state_dict(),\n",
        "    'config': {\n",
        "        'vocab_size': tokenizer.vocab_size,\n",
        "        'd_model': student_cfg['d_model'],\n",
        "        'n_layers': student_cfg['n_layers'],\n",
        "        'n_heads': student_cfg['n_heads'],\n",
        "        'd_ff': student_cfg['d_ff'],\n",
        "        'max_seq_len': config.max_length,\n",
        "    },\n",
        "    'training_history': history,\n",
        "}, os.path.join(config.output_dir, 'fraud_slm_final.pt'))\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(config.output_dir)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Model Saved\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nüìÅ Output directory: {config.output_dir}\")\n",
        "print(f\"   - fraud_slm_final.pt (model weights)\")\n",
        "print(f\"   - tokenizer files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1c40ee5",
      "metadata": {
        "id": "d1c40ee5"
      },
      "source": [
        "## 8. Test Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a99ebed",
      "metadata": {
        "id": "9a99ebed"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# TEST STUDENT MODEL\n",
        "# ============================================================================\n",
        "\n",
        "student_model.eval()\n",
        "\n",
        "def predict_fraud(model, tokenizer, prompt: str, device) -> str:\n",
        "    \"\"\"Generate fraud prediction from student model\"\"\"\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=config.max_length,\n",
        "        padding=True,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "        # Get next token prediction\n",
        "        next_token_logits = logits[0, -1, :]\n",
        "        next_token_id = next_token_logits.argmax().item()\n",
        "        predicted_token = tokenizer.decode([next_token_id])\n",
        "\n",
        "    # Determine prediction\n",
        "    if 'FRAUD' in predicted_token.upper() or 'fraud' in predicted_token.lower():\n",
        "        return 'FRAUD'\n",
        "    elif 'LEGIT' in predicted_token.upper() or 'legit' in predicted_token.lower():\n",
        "        return 'LEGITIMATE'\n",
        "    else:\n",
        "        # Use logits for FRAUD/LEGITIMATE tokens\n",
        "        fraud_tokens = tokenizer.encode('FRAUD', add_special_tokens=False)\n",
        "        legit_tokens = tokenizer.encode('LEGITIMATE', add_special_tokens=False)\n",
        "\n",
        "        fraud_score = next_token_logits[fraud_tokens[0]].item() if fraud_tokens else 0\n",
        "        legit_score = next_token_logits[legit_tokens[0]].item() if legit_tokens else 0\n",
        "\n",
        "        return 'FRAUD' if fraud_score > legit_score else 'LEGITIMATE'\n",
        "\n",
        "\n",
        "# Test cases\n",
        "test_cases = [\n",
        "    {'merchant': 'Starbucks', 'amount': 12.50, 'expected': 'LEGITIMATE'},\n",
        "    {'merchant': 'Wire Transfer Intl', 'amount': 9500, 'expected': 'FRAUD'},\n",
        "    {'merchant': 'Amazon', 'amount': 150, 'expected': 'LEGITIMATE'},\n",
        "    {'merchant': 'Crypto Exchange', 'amount': 15000, 'expected': 'FRAUD'},\n",
        "    {'merchant': 'Whole Foods', 'amount': 85, 'expected': 'LEGITIMATE'},\n",
        "]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Student Model Predictions\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "correct = 0\n",
        "for i, test in enumerate(test_cases):\n",
        "    # Create test prompt\n",
        "    prompt = f\"\"\"<|system|>\n",
        "You are a fraud detection system.\n",
        "<|user|>\n",
        "Transaction: {test['merchant']}, ${test['amount']}\n",
        "Is this FRAUD or LEGITIMATE?\n",
        "<|assistant|>\n",
        "Based on the transaction, this is: \"\"\"\n",
        "\n",
        "    prediction = predict_fraud(student_model, tokenizer, prompt, device)\n",
        "    is_correct = prediction == test['expected']\n",
        "    correct += int(is_correct)\n",
        "\n",
        "    icon = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
        "    print(f\"\\n{i+1}. {test['merchant']} - ${test['amount']}\")\n",
        "    print(f\"   Expected: {test['expected']}\")\n",
        "    print(f\"   Predicted: {prediction} {icon}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(f\"Accuracy: {correct}/{len(test_cases)} ({100*correct/len(test_cases):.0f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd2b551",
      "metadata": {
        "id": "4bd2b551"
      },
      "source": [
        "## 9. Performance Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb3a8ce",
      "metadata": {
        "id": "cfb3a8ce"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PERFORMANCE BENCHMARK\n",
        "# ============================================================================\n",
        "\n",
        "import time\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Performance Benchmark: Student vs Teacher\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test prompt\n",
        "test_prompt = \"\"\"<|system|>\n",
        "You are a fraud detection system.\n",
        "<|user|>\n",
        "Transaction: Amazon, $150\n",
        "Is this FRAUD or LEGITIMATE?\n",
        "<|assistant|>\n",
        "Based on the transaction, this is: \"\"\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "    test_prompt,\n",
        "    return_tensors='pt',\n",
        "    truncation=True,\n",
        "    max_length=config.max_length,\n",
        "    padding=True,\n",
        ").to(device)\n",
        "\n",
        "NUM_RUNS = 100\n",
        "\n",
        "# Benchmark Student Model\n",
        "student_model.eval()\n",
        "torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "\n",
        "start = time.time()\n",
        "for _ in range(NUM_RUNS):\n",
        "    with torch.no_grad():\n",
        "        _ = student_model(inputs['input_ids'], inputs['attention_mask'])\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "student_time = (time.time() - start) / NUM_RUNS * 1000  # ms\n",
        "\n",
        "# Benchmark Teacher Model\n",
        "start = time.time()\n",
        "for _ in range(NUM_RUNS):\n",
        "    with torch.no_grad():\n",
        "        _ = teacher_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "teacher_time = (time.time() - start) / NUM_RUNS * 1000  # ms\n",
        "\n",
        "# Results\n",
        "speedup = teacher_time / student_time\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  Inference Latency (avg over {NUM_RUNS} runs):\")\n",
        "print(f\"   Student ({student_cfg['params']}): {student_time:.2f} ms\")\n",
        "print(f\"   Teacher (7B): {teacher_time:.2f} ms\")\n",
        "print(f\"\\nüöÄ Speedup: {speedup:.1f}x faster\")\n",
        "\n",
        "# Memory comparison\n",
        "student_memory = sum(p.numel() * p.element_size() for p in student_model.parameters()) / 1e6\n",
        "teacher_memory = 7000  # ~7GB for Mistral-7B (estimate)\n",
        "\n",
        "print(f\"\\nüíæ Memory Footprint:\")\n",
        "print(f\"   Student: ~{student_memory:.0f} MB\")\n",
        "print(f\"   Teacher: ~{teacher_memory} MB\")\n",
        "print(f\"   Reduction: {teacher_memory/student_memory:.0f}x smaller\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "861aa878",
      "metadata": {
        "id": "861aa878"
      },
      "source": [
        "## 10. Export for Production (TensorRT / ONNX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf13769",
      "metadata": {
        "id": "5cf13769"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# EXPORT TO ONNX FOR TENSORRT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Exporting Student Model to ONNX\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Prepare dummy input\n",
        "dummy_input_ids = torch.randint(0, tokenizer.vocab_size, (1, config.max_length)).to(device)\n",
        "dummy_attention_mask = torch.ones(1, config.max_length).to(device)\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_path = os.path.join(config.output_dir, 'fraud_slm.onnx')\n",
        "\n",
        "student_model.eval()\n",
        "with torch.no_grad():\n",
        "    torch.onnx.export(\n",
        "        student_model,\n",
        "        (dummy_input_ids, dummy_attention_mask),\n",
        "        onnx_path,\n",
        "        input_names=['input_ids', 'attention_mask'],\n",
        "        output_names=['logits'],\n",
        "        dynamic_axes={\n",
        "            'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
        "            'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
        "            'logits': {0: 'batch_size', 1: 'sequence'},\n",
        "        },\n",
        "        opset_version=14,\n",
        "        do_constant_folding=True,\n",
        "    )\n",
        "\n",
        "onnx_size = os.path.getsize(onnx_path) / 1e6\n",
        "\n",
        "print(f\"\\n‚úÖ ONNX model exported:\")\n",
        "print(f\"   Path: {onnx_path}\")\n",
        "print(f\"   Size: {onnx_size:.1f} MB\")\n",
        "\n",
        "print(f\"\\nüìù TensorRT Conversion (run in terminal):\")\n",
        "print(f\"   trtexec --onnx={onnx_path} --saveEngine=fraud_slm.trt --fp16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b05d297",
      "metadata": {
        "id": "3b05d297"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d78f17e",
      "metadata": {
        "id": "5d78f17e"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ KNOWLEDGE DISTILLATION COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\"\"\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  SOLUTION SUMMARY                                                   ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ                                                                     ‚îÇ\n",
        "‚îÇ  üéì TEACHER MODEL                                                   ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Mistral-7B (7B parameters)                                   ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Used to generate soft labels                                 ‚îÇ\n",
        "‚îÇ                                                                     ‚îÇ\n",
        "‚îÇ  üéí STUDENT MODEL                                                   ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Size: {config.student_size.upper()} ({student_cfg['params']})                                   ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Architecture: {student_cfg['n_layers']} layers, {student_cfg['n_heads']} heads, d={student_cfg['d_model']}                 ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Compression: {7e9/total_params:.0f}x smaller than teacher                            ‚îÇ\n",
        "‚îÇ                                                                     ‚îÇ\n",
        "‚îÇ  üìä TRAINING                                                        ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Dataset: 10,000 fraud detection samples                      ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Method: Knowledge Distillation (Œ±={config.alpha}, T={config.temperature})             ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Epochs: {config.num_epochs}                                                       ‚îÇ\n",
        "‚îÇ                                                                     ‚îÇ\n",
        "‚îÇ  üöÄ PERFORMANCE                                                     ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Inference: {student_time:.1f}ms ({speedup:.0f}x faster than teacher)                ‚îÇ\n",
        "‚îÇ     ‚Ä¢ Memory: {student_memory:.0f}MB ({teacher_memory/student_memory:.0f}x smaller)                                 ‚îÇ\n",
        "‚îÇ                                                                     ‚îÇ\n",
        "‚îÇ  üìÅ OUTPUT FILES                                                    ‚îÇ\n",
        "‚îÇ     ‚Ä¢ {config.output_dir}/fraud_slm_final.pt                      ‚îÇ\n",
        "‚îÇ     ‚Ä¢ {config.output_dir}/fraud_slm.onnx                          ‚îÇ\n",
        "‚îÇ     ‚Ä¢ {config.output_dir}/tokenizer files                         ‚îÇ\n",
        "‚îÇ                                                                     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "üéØ NEXT STEPS:\n",
        "   1. Convert ONNX to TensorRT for even faster inference\n",
        "   2. Deploy with vLLM or TensorRT-LLM\n",
        "   3. Fine-tune on real production data\n",
        "   4. Add monitoring and A/B testing\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8827dc3d417140099791f7b31f68cc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d40b7dbdeb5c4359b9d4555ae70dc12d",
              "IPY_MODEL_d9a5528279f649dc97eecb12fe748b0a",
              "IPY_MODEL_587045d2db0041ecb72895eee406bd27"
            ],
            "layout": "IPY_MODEL_82c6c918b7344bfabfcddc8caf19d25f"
          }
        },
        "d40b7dbdeb5c4359b9d4555ae70dc12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb50b99d0764c25b9f7d5bbb6f358d5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e59b3078260a4e028c62ea4c3b34cc50",
            "value": "model.safetensors.index.json:‚Äá"
          }
        },
        "d9a5528279f649dc97eecb12fe748b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de2ce0e88e249b1814d8360e1b51ed6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcc9d1f713d7461595b97bd6835ab30d",
            "value": 1
          }
        },
        "587045d2db0041ecb72895eee406bd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89fff611cb248329b6d451fd04341a8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_130e7429d0ab49958005dab8d9fcc9fc",
            "value": "‚Äá25.1k/?‚Äá[00:00&lt;00:00,‚Äá2.78MB/s]"
          }
        },
        "82c6c918b7344bfabfcddc8caf19d25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb50b99d0764c25b9f7d5bbb6f358d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e59b3078260a4e028c62ea4c3b34cc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1de2ce0e88e249b1814d8360e1b51ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dcc9d1f713d7461595b97bd6835ab30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b89fff611cb248329b6d451fd04341a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130e7429d0ab49958005dab8d9fcc9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c11bed3b69db4648b1c94ea9fad9ffb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b25e626579b54f918aad88d7810b3308",
              "IPY_MODEL_c539ad5a904a427a95092881105b947d",
              "IPY_MODEL_e909537c900e456199b31b4f71668c74"
            ],
            "layout": "IPY_MODEL_cd17220981c545958da82f567c0bc3fc"
          }
        },
        "b25e626579b54f918aad88d7810b3308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab9495e3a9b420383717902899a3557",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bf000801bc7541d9bd37aa66e4e3682c",
            "value": "Fetching‚Äá2‚Äáfiles:‚Äá100%"
          }
        },
        "c539ad5a904a427a95092881105b947d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecb9c037aa3b4487995de13fe9973435",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_786b315733754913ae58ffacb1207eb3",
            "value": 2
          }
        },
        "e909537c900e456199b31b4f71668c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ef0be5d6ef4e6cac6506403160fe41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_108ae18cf36d4cb089a90d5055241c53",
            "value": "‚Äá2/2‚Äá[00:38&lt;00:00,‚Äá38.58s/it]"
          }
        },
        "cd17220981c545958da82f567c0bc3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab9495e3a9b420383717902899a3557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf000801bc7541d9bd37aa66e4e3682c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecb9c037aa3b4487995de13fe9973435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786b315733754913ae58ffacb1207eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33ef0be5d6ef4e6cac6506403160fe41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108ae18cf36d4cb089a90d5055241c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1448392265e7465895588459f5a25185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efaadf4823f145fbb706fb1a33bf012c",
              "IPY_MODEL_f493162ea28b46d6b0126a3420ee19bb",
              "IPY_MODEL_68b604ea78ca4e50ad4e6de310c06844"
            ],
            "layout": "IPY_MODEL_55cc2155088844c48e6be67f501269c2"
          }
        },
        "efaadf4823f145fbb706fb1a33bf012c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11f156600b8b40348de9a5ef5f88e751",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6a69ed3cb4b048d59fa6ead734e0f661",
            "value": "model-00002-of-00002.safetensors:‚Äá100%"
          }
        },
        "f493162ea28b46d6b0126a3420ee19bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_977f3c9c67a84fc6a9cb0801df5351f9",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb322ad1e9414b908133cc44c9b8cf58",
            "value": 4540516344
          }
        },
        "68b604ea78ca4e50ad4e6de310c06844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f7bd953c56426ea595fde62e526cdf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cb179d85a75441138082347b48f942e8",
            "value": "‚Äá4.54G/4.54G‚Äá[00:26&lt;00:00,‚Äá91.1MB/s]"
          }
        },
        "55cc2155088844c48e6be67f501269c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f156600b8b40348de9a5ef5f88e751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a69ed3cb4b048d59fa6ead734e0f661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "977f3c9c67a84fc6a9cb0801df5351f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb322ad1e9414b908133cc44c9b8cf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15f7bd953c56426ea595fde62e526cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb179d85a75441138082347b48f942e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6d142e6083149b9b49abeee3f2f3f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7879caa643e64a90b54b1e44f9403a87",
              "IPY_MODEL_2169fea9afa14d7a908fd910e8cfabcc",
              "IPY_MODEL_1fa39fa6987c4da18fa333e82f24240e"
            ],
            "layout": "IPY_MODEL_bf5f2dcffabb40f3bfbb83d8a7f22b43"
          }
        },
        "7879caa643e64a90b54b1e44f9403a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b05167f92bb54283b32ac9b316806f56",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d49d89150c3a4f1fb145527486fbef7f",
            "value": "model-00001-of-00002.safetensors:‚Äá100%"
          }
        },
        "2169fea9afa14d7a908fd910e8cfabcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5e98b6ff3a4a6a92ad75f3c6094ef4",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b247ee29c6f4f15a063026a5d585477",
            "value": 9942981696
          }
        },
        "1fa39fa6987c4da18fa333e82f24240e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3c8fb69e064517846966dae503931d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7bf0bbb6247e415e8b5f986556ac7dab",
            "value": "‚Äá9.94G/9.94G‚Äá[00:38&lt;00:00,‚Äá835MB/s]"
          }
        },
        "bf5f2dcffabb40f3bfbb83d8a7f22b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b05167f92bb54283b32ac9b316806f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49d89150c3a4f1fb145527486fbef7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba5e98b6ff3a4a6a92ad75f3c6094ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b247ee29c6f4f15a063026a5d585477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a3c8fb69e064517846966dae503931d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf0bbb6247e415e8b5f986556ac7dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88eae737800940d782d615334cb0e8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbbbd4400ef74df89e2aedf352c539cc",
              "IPY_MODEL_7aada6e682e94b3c9f7d88c417c48ea5",
              "IPY_MODEL_42e119d315084de484ca9bd38fab2859"
            ],
            "layout": "IPY_MODEL_57c1e8ab872a49359ff8532c0ac6518a"
          }
        },
        "dbbbd4400ef74df89e2aedf352c539cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a572f01d4d0b419b855ec46a012c6a6f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b9a8f8e5653f4baeaca353d1b599e450",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "7aada6e682e94b3c9f7d88c417c48ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e583691e198e46988345fc4c4f073a1a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7258539794ac4cb3ae65dc58dc1d4f7a",
            "value": 2
          }
        },
        "42e119d315084de484ca9bd38fab2859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546f8e2a055244f3b2b0a088188d88cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1e2e837adf0744339408332ab970ff0a",
            "value": "‚Äá2/2‚Äá[00:16&lt;00:00,‚Äá‚Äá7.72s/it]"
          }
        },
        "57c1e8ab872a49359ff8532c0ac6518a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a572f01d4d0b419b855ec46a012c6a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a8f8e5653f4baeaca353d1b599e450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e583691e198e46988345fc4c4f073a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7258539794ac4cb3ae65dc58dc1d4f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "546f8e2a055244f3b2b0a088188d88cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2e837adf0744339408332ab970ff0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f028a8721f04ec7883af679ebc19cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8bf841b9b6247c38e87c04077f7d5a6",
              "IPY_MODEL_aac3d996a6df4ae98d1eb2a9e4cdf038",
              "IPY_MODEL_f654ad61647d4a719f03c29b8fac535d"
            ],
            "layout": "IPY_MODEL_5a58b78752be4895b27f3b3de2b1d6cd"
          }
        },
        "e8bf841b9b6247c38e87c04077f7d5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50c757282bcb426bbb575e4c87607c3f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_060e3079a5f14f7082f7d12dd211871d",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "aac3d996a6df4ae98d1eb2a9e4cdf038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d4ec50f98d45de8f7fa30fbfe5aed8",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_058e6672ab4d4bfea3515808f7f6e095",
            "value": 116
          }
        },
        "f654ad61647d4a719f03c29b8fac535d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_157f5a2ff62f4fd3b2df844fd9759edb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dc8e077b90994f44b705e0b9108213ee",
            "value": "‚Äá116/116‚Äá[00:00&lt;00:00,‚Äá16.4kB/s]"
          }
        },
        "5a58b78752be4895b27f3b3de2b1d6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c757282bcb426bbb575e4c87607c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "060e3079a5f14f7082f7d12dd211871d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d4ec50f98d45de8f7fa30fbfe5aed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058e6672ab4d4bfea3515808f7f6e095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "157f5a2ff62f4fd3b2df844fd9759edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc8e077b90994f44b705e0b9108213ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}